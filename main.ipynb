{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.layers import Conv2D, Dropout, Concatenate,Average, BatchNormalization, MaxPooling2D, Flatten\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import h5py\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "FIXED_LENGTH_FOR_TRAINING = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAMES = ['Audio_Transcript','Title','Tags','Comments','Thumbnail','Video']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_model = load_model('final_model/combined_model.h5')\n",
    "AT_tokenizer = pickle.load(open('final_model/audio_transcript_tokenizer.pkl', 'rb') )\n",
    "T_tokenizer = pickle.load(open('final_model/title_tokenizer.pkl', 'rb') )\n",
    "TAGS_tokenizer = pickle.load(open('final_model/tags_tokenizer.pkl', 'rb') )\n",
    "C_tokenizer = pickle.load(open('final_model/comments_tokenizer.pkl', 'rb') )\n",
    "\n",
    "STATS_labelencoder = pickle.load(open('final_model/stats_labelencoder.pkl', 'rb') )\n",
    "STATS_sc = pickle.load(open('final_model/stats_scaler.pkl', 'rb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "TB_IN (InputLayer)              (None, 90, 120, 3)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 90, 120, 64)  1792        TB_IN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 90, 120, 64)  36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 45, 60, 64)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 45, 60, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 45, 60, 128)  147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 22, 30, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 22, 30, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 22, 30, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 22, 30, 256)  590080      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 11, 15, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 11, 15, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 11, 15, 512)  2359808     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 11, 15, 512)  2359808     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 7, 512)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 5, 7, 512)    2359808     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 5, 7, 512)    2359808     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 5, 7, 512)    2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "STATS_IN (InputLayer)           (None, 7)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 2, 3, 512)    0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "AT_IN (InputLayer)              (None, 3000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "T_IN (InputLayer)               (None, 3000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "TAGS_IN (InputLayer)            (None, 3000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "C_IN (InputLayer)               (None, 3000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "STATS_1 (Dense)                 (None, 10)           80          STATS_IN[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3072)         0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 3000, 100)    5000000     AT_IN[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 3000, 100)    5000000     T_IN[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 3000, 100)    5000000     TAGS_IN[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 3000, 100)    5000000     C_IN[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 10)           40          STATS_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4096)         12587008    flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_1 (SpatialDro (None, 3000, 100)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, 3000, 100)    0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 3000, 100)    0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_4 (SpatialDro (None, 3000, 100)    0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "STATS_2 (Dense)                 (None, 100)          1100        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4096)         16781312    dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AT_LSTM (LSTM)                  (None, 100)          80400       spatial_dropout1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "T_LSTM (LSTM)                   (None, 100)          80400       spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "TAGS_LSTM (LSTM)                (None, 100)          80400       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "C_LSTM (LSTM)                   (None, 100)          80400       spatial_dropout1d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 100)          400         STATS_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          409700      dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_1 (Average)             (None, 100)          0           AT_LSTM[0][0]                    \n",
      "                                                                 T_LSTM[0][0]                     \n",
      "                                                                 TAGS_LSTM[0][0]                  \n",
      "                                                                 C_LSTM[0][0]                     \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 300)          30300       average_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 300)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "AT_OUT (Dense)                  (None, 2)            202         AT_LSTM[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "T_OUT (Dense)                   (None, 2)            202         T_LSTM[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "TAGS_OUT (Dense)                (None, 2)            202         TAGS_LSTM[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "C_OUT (Dense)                   (None, 2)            202         C_LSTM[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "STATS_OUT (Dense)               (None, 2)            202         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "TB_OUT (Dense)                  (None, 2)            202         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "FINAL_OUT (Dense)               (None, 2)            602         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 64,848,042\n",
      "Trainable params: 35,306\n",
      "Non-trainable params: 64,812,736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MERGED_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Audio Transcript Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_model.get_layer('embedding_1').set_weights(np.load('audio_transcript/embedding.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('AT_LSTM').set_weights(np.load('audio_transcript/lstm.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('AT_OUT').set_weights(np.load('audio_transcript/dense.npy', allow_pickle = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Title Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_model.get_layer('embedding_2').set_weights(np.load('title/embedding.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('T_LSTM').set_weights(np.load('title/lstm.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('T_OUT').set_weights(np.load('title/dense.npy', allow_pickle = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Tags Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_model.get_layer('embedding_3').set_weights(np.load('tags/embedding.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('TAGS_LSTM').set_weights(np.load('title/lstm.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('TAGS_OUT').set_weights(np.load('title/dense.npy', allow_pickle = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Comments Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_model.get_layer('embedding_4').set_weights(np.load('comments/embedding.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('C_LSTM').set_weights(np.load('title/lstm.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('C_OUT').set_weights(np.load('title/dense.npy', allow_pickle = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Stats Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_model.get_layer('STATS_1').set_weights(np.load('stats/dense_1.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('STATS_2').set_weights(np.load('title/dense_2.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('STATS_OUT').set_weights(np.load('title/dense_3.npy', allow_pickle = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Thumbnail Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_model.get_layer('conv2d_1').set_weights(np.load('comments/conv_1.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_2').set_weights(np.load('comments/conv_2.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_3').set_weights(np.load('comments/conv_3.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_4').set_weights(np.load('comments/conv_4.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_5').set_weights(np.load('comments/conv_5.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_6').set_weights(np.load('comments/conv_6.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_7').set_weights(np.load('comments/conv_7.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_8').set_weights(np.load('comments/conv_8.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_9').set_weights(np.load('comments/conv_9.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_10').set_weights(np.load('comments/conv_10.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_11').set_weights(np.load('comments/conv_11.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_12').set_weights(np.load('comments/conv_12.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('conv2d_13').set_weights(np.load('comments/conv_13.npy', allow_pickle = True))\n",
    "\n",
    "\n",
    "MERGED_model.get_layer('dense_1').set_weights(np.load('comments/dense_1.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('dense_2').set_weights(np.load('comments/dense_2.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('dense_3').set_weights(np.load('comments/dense_3.npy', allow_pickle = True))\n",
    "MERGED_model.get_layer('TB_OUT').set_weights(np.load('comments/dense_4.npy', allow_pickle = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Video Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_model/Data.csv')\n",
    "audio_data = pd.read_csv('audio_transcript/Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:FIXED_LENGTH_FOR_TRAINING]\n",
    "audio_data = audio_data.iloc[:FIXED_LENGTH_FOR_TRAINING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGS_X_train = np.load('thumbnail/train_images.npy')\n",
    "IMGS_y_train = np.load('thumbnail/train_labels.npy')\n",
    "\n",
    "IMGS_X_test = np.load('thumbnail/test_images.npy')\n",
    "IMGS_y_test = np.load('thumbnail/test_labels.npy')\n",
    "\n",
    "# train_path = 'thumbnail/data/train'\n",
    "# test_path = 'thumbnail/data/test'\n",
    "# train_batches = ImageDataGenerator().flow_from_directory(train_path,target_size=(90, 120),classes=['cb','ncb'],batch_size = 32)\n",
    "# test_batches = ImageDataGenerator().flow_from_directory(test_path,target_size=(90, 120),classes=['cb','ncb'],batch_size = 32)\n",
    "\n",
    "# count = 0\n",
    "# train_imgs,train_labels = next(train_batches)\n",
    "# for batch in train_batches:\n",
    "    \n",
    "#     a,b = batch\n",
    "#     train_imgs = np.concatenate((train_imgs , a), axis = 0)\n",
    "#     train_labels = np.concatenate((train_labels , b), axis = 0)\n",
    "#     count += 1\n",
    "#     print(train_imgs.shape)\n",
    "    \n",
    "#     if (train_imgs.shape[0] > 13499):\n",
    "#         break\n",
    "# #     print(str(count))\n",
    "\n",
    "# count = 0\n",
    "# test_imgs,test_labels = next(test_batches)\n",
    "# for batch in test_batches:\n",
    "#     a,b = batch\n",
    "#     test_imgs = np.concatenate((test_imgs , a), axis = 0)\n",
    "#     test_labels = np.concatenate((test_labels , b), axis = 0)\n",
    "#     count += 1\n",
    "#     print(test_imgs.shape)\n",
    "\n",
    "#     if (test_imgs.shape[0] > 1499):\n",
    "#         break\n",
    "        \n",
    "# np.save('thumbnail/train_images.npy', train_imgs)\n",
    "# np.save('thumbnail/train_labels.npy', train_labels)\n",
    "# np.save('thumbnail/test_images.npy', test_imgs)\n",
    "# np.save('thumbnail/test_labels.npy', test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        \n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    if type(text) == float:\n",
    "        text = str(text)\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
    "    text = text.replace('x', '')\n",
    "    # text = re.sub(r'\\W+', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_timestamp(s):\n",
    "    return time.mktime(datetime.datetime.strptime(s, \"%Y-%m-%dT%H:%M:%S.000Z\").timetuple())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_data = audio_data.reset_index(drop=True)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Transcript\n",
    "audio_data['Audio_Transcript'] = audio_data['Audio_Transcript'].apply(clean_text)\n",
    "audio_data['Audio_Transcript'] = audio_data['Audio_Transcript'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title\n",
    "df['Title'] = df['Title'].apply(clean_text)\n",
    "df['Title'] = df['Title'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tags\n",
    "df['Tags'] = df['Tags'].apply(clean_text)\n",
    "df['Tags'] = df['Tags'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments\n",
    "df['Comments'] = df['Comments'].apply(clean_text)\n",
    "df['Comments'] = df['Comments'].str.replace('\\d+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stats\n",
    "df['Date'] = df['Date'].apply(convert_to_timestamp)\n",
    "df['Duration'].replace('None', np.nan, inplace=True)\n",
    "\n",
    "df['Date'].replace('PT1M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT2M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT3M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT4M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT5M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT6M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT7M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT8M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT9M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT10M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT11M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT12M', np.nan, inplace=True)\n",
    "df['Date'].replace('PT13M', np.nan, inplace=True)\n",
    "\n",
    "pd.to_numeric(df['Duration'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split to Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AT_MAX_SEQUENCE_LENGTH = 3000\n",
    "AT_tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "AT_tokenizer.fit_on_texts(audio_data['Audio_Transcript'].values)\n",
    "word_index = AT_tokenizer.word_index\n",
    "# print('Found %s unique tokens.' % len(word_index))\n",
    "AT_X = AT_tokenizer.texts_to_sequences(audio_data['Audio_Transcript'].values)\n",
    "AT_X = pad_sequences(AT_X, maxlen=AT_MAX_SEQUENCE_LENGTH)\n",
    "# print('Shape of data tensor:', AT_X.shape)\n",
    "AT_Y = pd.get_dummies(audio_data['Label']).values\n",
    "# print('Shape of label tensor:', AT_Y.shape)\n",
    "AT_X_train, AT_X_test, AT_Y_train, AT_Y_test = train_test_split(AT_X,AT_Y, test_size = 0.10, random_state = 42)\n",
    "print(AT_X_train.shape,AT_Y_train.shape)\n",
    "print(AT_X_test.shape,AT_Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_MAX_SEQUENCE_LENGTH = 3000\n",
    "T_tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "T_tokenizer.fit_on_texts(df['Title'].values)\n",
    "word_index = T_tokenizer.word_index\n",
    "# print('Found %s unique tokens.' % len(word_index))\n",
    "T_X = T_tokenizer.texts_to_sequences(df['Title'].values)\n",
    "T_X = pad_sequences(T_X, maxlen=T_MAX_SEQUENCE_LENGTH)\n",
    "# print('Shape of data tensor:', AT_X.shape)\n",
    "Y = pd.get_dummies(df['Label']).values\n",
    "# print('Shape of label tensor:', AT_Y.shape)\n",
    "T_X_train, T_X_test, T_Y_train, T_Y_test = train_test_split(T_X,Y , test_size = 0.10, random_state = 42)\n",
    "print(T_X_train.shape,T_Y_train.shape)\n",
    "print(T_X_test.shape,T_Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS_MAX_SEQUENCE_LENGTH = 3000\n",
    "TAGS_tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "TAGS_tokenizer.fit_on_texts(df['Tags'].values)\n",
    "word_index = TAGS_tokenizer.word_index\n",
    "# print('Found %s unique tokens.' % len(word_index))\n",
    "TAGS_X = TAGS_tokenizer.texts_to_sequences(df['Tags'].values)\n",
    "TAGS_X = pad_sequences(TAGS_X, maxlen=TAGS_MAX_SEQUENCE_LENGTH)\n",
    "# print('Shape of data tensor:', AT_X.shape)\n",
    "# T_Y = pd.get_dummies(df['Label']).values\n",
    "# print('Shape of label tensor:', AT_Y.shape)\n",
    "TAGS_X_train, TAGS_X_test, TAGS_Y_train, TAGS_Y_test = train_test_split(T_X,Y, test_size = 0.10, random_state = 42)\n",
    "print(TAGS_X_train.shape,TAGS_Y_train.shape)\n",
    "print(TAGS_X_test.shape,TAGS_Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_MAX_SEQUENCE_LENGTH = 3000\n",
    "C_tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "C_tokenizer.fit_on_texts(df['Comments'].values)\n",
    "word_index = C_tokenizer.word_index\n",
    "# print('Found %s unique tokens.' % len(word_index))\n",
    "C_X = C_tokenizer.texts_to_sequences(df['Comments'].values)\n",
    "C_X = pad_sequences(C_X, maxlen=C_MAX_SEQUENCE_LENGTH)\n",
    "# print('Shape of data tensor:', AT_X.shape)\n",
    "# T_Y = pd.get_dummies(df['Label']).values\n",
    "# print('Shape of label tensor:', AT_Y.shape)\n",
    "C_X_train, C_X_test, C_Y_train, C_Y_test = train_test_split(C_X,Y, test_size = 0.10, random_state = 42)\n",
    "print(C_X_train.shape,C_Y_train.shape)\n",
    "print(C_X_test.shape,C_Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS_X = df.iloc[:, 5:12].values\n",
    "# STATS_y = df.iloc[:, 0].values\n",
    "\n",
    "STATS_labelencoder = LabelEncoder()\n",
    "STATS_X[:, 1] = STATS_labelencoder.fit_transform(STATS_X[:, 1])\n",
    "\n",
    "STATS_X_train, STATS_X_test, STATS_Y_train, STATS_Y_test = train_test_split(STATS_X, Y, test_size = 0.10, random_state = 0)\n",
    "\n",
    "STATS_SC = StandardScaler()\n",
    "STATS_X_train = STATS_SC.fit_transform(STATS_X_train)\n",
    "STATS_X_test = STATS_SC.transform(STATS_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thumbnail\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AT_IN = Input(shape=(AT_MAX_SEQUENCE_LENGTH,), name='AT_IN')\n",
    "AT_EMB = Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=AT_X.shape[1], trainable = False) (AT_IN)\n",
    "AT_SPD = SpatialDropout1D(0.5) (AT_EMB)\n",
    "AT_LSTM = LSTM(100, dropout=0.5, recurrent_dropout=0.2, name=\"AT_LSTM\", trainable = False) (AT_SPD)\n",
    "AT_OUT = Dense(2, activation='softmax', name='AT_OUT') (AT_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_IN = Input(shape=(T_MAX_SEQUENCE_LENGTH,), name='T_IN')\n",
    "T_EMB = Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=T_X.shape[1], trainable = False) (T_IN)\n",
    "T_SPD = SpatialDropout1D(0.5) (T_EMB)\n",
    "T_LSTM = LSTM(100, dropout=0.5, recurrent_dropout=0.2,name=\"T_LSTM\", trainable = False) (T_SPD)\n",
    "T_OUT = Dense(2, activation='softmax', name='T_OUT') (T_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS_IN = Input(shape=(T_MAX_SEQUENCE_LENGTH,), name='TAGS_IN')\n",
    "TAGS_EMB = Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=TAGS_X.shape[1], trainable = False) (TAGS_IN)\n",
    "TAGS_SPD = SpatialDropout1D(0.5) (TAGS_EMB)\n",
    "TAGS_LSTM = LSTM(100, dropout=0.5, recurrent_dropout=0.2,name=\"TAGS_LSTM\", trainable = False) (TAGS_SPD)\n",
    "TAGS_OUT = Dense(2, activation='softmax', name='TAGS_OUT') (TAGS_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_IN = Input(shape=(C_MAX_SEQUENCE_LENGTH,), name='C_IN')\n",
    "C_EMB = Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=C_X.shape[1], trainable = False) (C_IN)\n",
    "C_SPD = SpatialDropout1D(0.5) (C_EMB)\n",
    "C_LSTM = LSTM(100, dropout=0.5, recurrent_dropout=0.2,name=\"C_LSTM\", trainable = False) (C_SPD)\n",
    "C_OUT = Dense(2, activation='softmax', name='C_OUT') (C_LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATS_IN = Input(shape=(STATS_X.shape[1],), name='STATS_IN')\n",
    "STATS_1 = Dense(10, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='relu', name='STATS_1') (STATS_IN)\n",
    "STATS_BATCH_1 = BatchNormalization() (STATS_1)\n",
    "STATS_2 = Dense(100, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='relu', name='STATS_2') (STATS_BATCH_1)\n",
    "STATS_BATCH_2 = BatchNormalization() (STATS_2)\n",
    "STATS_OUT = Dense(2, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation='sigmoid', name='STATS_OUT') (STATS_BATCH_2)\n",
    "\n",
    "\n",
    "\n",
    "# STATS_IN = Sequential()\n",
    "# classifier.add(Dense(output_dim = 10, kernel_initializer='glorot_uniform', bias_initializer='zeros', activation = 'relu', input_dim = 7))\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(Dense(output_dim = 100,kernel_initializer='glorot_uniform', bias_initializer='zeros', activation = 'relu'))\n",
    "# classifier.add(BatchNormalization())\n",
    "# classifier.add(Dense(output_dim = 1,  kernel_initializer='glorot_uniform', bias_initializer='zeros', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thumbnail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TB_IN = Input(shape=(IMGS_X_train.shape[1],IMGS_X_train.shape[2],IMGS_X_train.shape[3],), name='TB_IN')\n",
    "TB_1 = Conv2D(64, (3, 3), padding='same', activation='relu') (TB_IN)\n",
    "TB_2 = Conv2D(64, (3, 3), activation='relu', padding='same', trainable = False) (TB_1)\n",
    "TB_3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2)) (TB_2)\n",
    "TB_4 = Conv2D(128, (3, 3), activation='relu', padding='same', trainable = False) (TB_3)\n",
    "TB_5 = Conv2D(128, (3, 3), activation='relu', padding='same', trainable = False) (TB_4)\n",
    "TB_6 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2)) (TB_5)\n",
    "TB_7 = Conv2D(256, (3, 3), activation='relu', padding='same', trainable = False) (TB_6)\n",
    "TB_8 = Conv2D(256, (3, 3), activation='relu', padding='same', trainable = False) (TB_7)\n",
    "TB_9 = Conv2D(256, (3, 3), activation='relu', padding='same', trainable = False) (TB_8)\n",
    "TB_10 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2)) (TB_9)\n",
    "TB_11 = Conv2D(512, (3, 3), activation='relu', padding='same', trainable = False) (TB_10)\n",
    "TB_12 = Conv2D(512, (3, 3), activation='relu', padding='same', trainable = False) (TB_11)\n",
    "TB_13 = Conv2D(512, (3, 3), activation='relu', padding='same', trainable = False) (TB_12)\n",
    "TB_14 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2)) (TB_13)\n",
    "TB_15 = Conv2D(512, (3, 3), activation='relu', padding='same', trainable = False) (TB_14)\n",
    "TB_16 = Conv2D(512, (3, 3), activation='relu', padding='same', trainable = False) (TB_15)\n",
    "TB_17 = Conv2D(512, (3, 3), activation='relu', padding='same', trainable = False) (TB_16)\n",
    "TB_18 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2)) (TB_17)\n",
    "TB_19 = Flatten() (TB_18)\n",
    "TB_20 = Dense(4096, activation='relu', trainable = False) (TB_19)\n",
    "TB_21 = Dense(4096, activation='relu', trainable = False) (TB_20)\n",
    "TB_DENSE = Dense(100, activation='relu', trainable = False ) (TB_21)\n",
    "TB_OUT = Dense(2, activation='softmax', name='TB_OUT') (TB_DENSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED = Average()([AT_LSTM, T_LSTM, TAGS_LSTM, C_LSTM, STATS_BATCH_2, TB_DENSE ])\n",
    "MERGED = Dense(300, activation='relu') (MERGED)\n",
    "MERGED = Dropout(0.2) (MERGED)\n",
    "MERGED = Dense(2, activation='softmax', name='FINAL_OUT') (MERGED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MERGED_model = Model(inputs=[AT_IN,T_IN, TAGS_IN, C_IN, STATS_IN, TB_IN],outputs=[AT_OUT,T_OUT,TAGS_OUT, C_OUT,STATS_OUT,TB_OUT,MERGED])\n",
    "MERGED_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "MERGED_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "history = MERGED_model.fit(\n",
    "    [AT_X_train,T_X_train, TAGS_X_train, C_X_train, STATS_X_train, IMGS_X_train],\n",
    "    [AT_Y_train,T_Y_train, TAGS_Y_train, C_Y_train, STATS_y_train, IMGS_y_train, T_Y_train],\n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', \n",
    "                             patience=3, \n",
    "                             min_delta=0.0001)\n",
    "              ]\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = MERGED_model.evaluate([AT_X_test,T_X_test,TAGS_X_test, C_X_test, STATS_X_test,IMGS_X_test],\n",
    "                             [AT_Y_test,T_Y_test,TAGS_Y_test, C_Y_test, STATS_Y_test, IMGS_Y_test, T_Y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERGED_model.save('final_model/combined_model.h5')  # creates a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(AT_tokenizer, open('final_model/audio_transcript_tokenizer.pkl', 'wb') )\n",
    "pickle.dump(T_tokenizer, open('final_model/title_tokenizer.pkl', 'wb') )\n",
    "pickle.dump(TAGS_tokenizer, open('final_model/tags_tokenizer.pkl', 'wb') )\n",
    "pickle.dump(C_tokenizer, open('final_model/comments_tokenizer.pkl', 'wb') )\n",
    "\n",
    "pickle.dump(STATS_SC, open('final_model/stats_scaler.pkl', 'wb') )\n",
    "pickle.dump(STATS_labelencoder, open('final_model/stats_labelencoder.pkl', 'wb') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_video = {\n",
    "    \"title\" : 'Formula 1 Engineering Tour',\n",
    "    \"audio_transcript\" : 'hello there my name is Jonathan Edels Im the chief race engineer for Scuderia Toro Rosso I believe a couple of weeks ago our chief mechanic Tommy took you around the the garage introduced you to the garage garage operations what goes on in there Im hopefully going to do something similar but from the engineer insight trackside sir Ive just introduced you to the the pit wall what',\n",
    "    'tags': '',\n",
    "    'comments': '',\n",
    "    'stats': '',\n",
    "    'thumbnail' : '',\n",
    "    'video' : ''\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AT_MAX_SEQUENCE_LENGTH = 3000\n",
    "A_seq = AT_tokenizer.texts_to_sequences([inference_video['audio_transcript']])\n",
    "AT_padded = pad_sequences(A_seq, maxlen=AT_MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "T_MAX_SEQUENCE_LENGTH = 3000\n",
    "T_seq = T_tokenizer.texts_to_sequences([inference_video['title']])\n",
    "T_padded = pad_sequences(T_seq, maxlen=T_MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "TAGS_MAX_SEQUENCE_LENGTH = 3000\n",
    "TAGS_seq = TAGS_tokenizer.texts_to_sequences([inference_video['tags']])\n",
    "TAGS_padded = pad_sequences(TAGS_seq, maxlen=T_MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "C_MAX_SEQUENCE_LENGTH = 3000\n",
    "C_seq = C_tokenizer.texts_to_sequences([inference_video['tags']])\n",
    "C_padded = pad_sequences(C_seq, maxlen=C_MAX_SEQUENCE_LENGTH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "pred = MERGED_model.predict([AT_padded,T_padded, TAGS_padded, C_padded], verbose=1, steps=1)\n",
    "\n",
    "time_taken = time.time() - start\n",
    "labels = [\"Non-ClickBait\",\"ClickBait\"]\n",
    "\n",
    "print(\"Time Taken to predict : \" + str(time_taken))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
